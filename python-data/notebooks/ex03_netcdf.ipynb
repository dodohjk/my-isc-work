{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Exercise 3: Reading and Writing NetCDF files with Python\n",
    "\n",
    "## Aim: Introduce the netCDF4 library in Python to read and create NetCDF4 files.\n",
    "\n",
    "### Issues covered:\n",
    "\n",
    "- Importing netCDF4\n",
    "- Reading a NetCDF file as a Dataset instance\n",
    "- Accessing Dimensions, Variables, and Attributes\n",
    "- Defining Dimensions, Variables, and Attributes\n",
    "- Writing a NetCDF file as a Dataset\n",
    "\n",
    "## Let's work with the netCDF4 library to examine the contents of a data file.\n",
    "\n",
    "Import the `netCDF4` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'netCDF4' from '/opt/jaspy/lib/python3.10/site-packages/netCDF4/__init__.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import netCDF4 as nc\n",
    "nc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file \"../example_data/ggas2014121200_00-18.nc\" with the netCDF4 `Dataset` method,\n",
    "assign it to the `ds` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ds = nc.Dataset('../example_data/ggas2014121200_00-18.nc')\n",
    "ds.variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through and print Dataset `variables` names, this is the ID that act like the key to access the Variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longitude\n",
      "latitude\n",
      "surface\n",
      "time\n",
      "CI\n",
      "SSTK\n",
      "MSL\n",
      "TCC\n",
      "U10\n",
      "V10\n",
      "SKT\n"
     ]
    }
   ],
   "source": [
    "for key in ds.variables.keys(): print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Dataset'>\n",
       "root group (NETCDF3_CLASSIC data model, file format NETCDF3):\n",
       "    CDI: Climate Data Interface version 1.5.6 (http://code.zmaw.de/projects/cdi)\n",
       "    Conventions: CF-1.4\n",
       "    history: Fri Apr 10 10:42:46 2015: cdo selname,SSTK,CI,U10,V10,TCC,SKT,MSL example_data/ggas2014121200_00-18_all_vars.nc example_data/ggas2014121200_00-18.nc\n",
       "Fri Apr 10 10:42:13 2015: cdo mergetime /badc/ecmwf-era-interim/data/gg/as/2014/12/12/ggas201412120000.nc /badc/ecmwf-era-interim/data/gg/as/2014/12/12/ggas201412120600.nc /badc/ecmwf-era-interim/data/gg/as/2014/12/12/ggas201412121200.nc /badc/ecmwf-era-interim/data/gg/as/2014/12/12/ggas201412121800.nc example_data/ggas2014121200_00-18_all_vars.nc\n",
       "Sun Jan 11 11:15:19 GMT 2015 - CONVSH V1.92 16-February-2006\n",
       "    CDO: Climate Data Operators version 1.5.6.1 (http://code.zmaw.de/projects/cdo)\n",
       "    dimensions(sizes): longitude(512), latitude(256), surface(1), time(4)\n",
       "    variables(dimensions): float32 longitude(longitude), float32 latitude(latitude), float32 surface(surface), float64 time(time), float32 CI(time, surface, latitude, longitude), float32 SSTK(time, surface, latitude, longitude), float32 MSL(time, surface, latitude, longitude), float32 TCC(time, surface, latitude, longitude), float32 U10(time, surface, latitude, longitude), float32 V10(time, surface, latitude, longitude), float32 SKT(time, surface, latitude, longitude)\n",
       "    groups: "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From the Dataset `variables`, assign the key `SSTK` to the `sst` variable.\n",
    "Access the `SSTK` variable like you would a dictionary from `ds.variables`.\n",
    "\n",
    "- Print the `shape` and `size` of the `sst` variable\n",
    "- Loop through the `dimensions` of `sst` and print the dimension name and length.\n",
    "- Loop through the NetCDF attributes of `sst` and print the name and value.\n",
    "(use `sst.ncattrs()` to access the attributes and `getattr(sst, {attribute name})` to get the value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 1, 256, 512), 524288)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst = ds.variables['SSTK']\n",
    "sst.shape, sst.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time 4\n",
      "surface 7\n",
      "latitude 8\n",
      "longitude 9\n"
     ]
    }
   ],
   "source": [
    "for dim in sst.dimensions:\n",
    "    print(dim, len(dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'netCDF4._netCDF4.Variable'>\n",
       "float32 SSTK(time, surface, latitude, longitude)\n",
       "    long_name: Sea surface temperature\n",
       "    units: K\n",
       "    grid_type: gaussian\n",
       "    _FillValue: 2e+20\n",
       "    source: GRIB data\n",
       "    name: SSTK\n",
       "    title: Sea surface temperature\n",
       "    date: 12/12/14\n",
       "    time: 00:00\n",
       "unlimited dimensions: time\n",
       "current shape = (4, 1, 256, 512)\n",
       "filling on"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 1, 256, 512) 524288\n",
      "time 4\n",
      "surface 7\n",
      "latitude 8\n",
      "longitude 9\n",
      "long_name = Sea surface temperature\n",
      "units = K\n",
      "grid_type = gaussian\n",
      "_FillValue = 2.0000000400817547e+20\n",
      "source = GRIB data\n",
      "name = SSTK\n",
      "title = Sea surface temperature\n",
      "date = 12/12/14\n",
      "time = 00:00\n"
     ]
    }
   ],
   "source": [
    "sst = ds.variables[\"SSTK\"]\n",
    "\n",
    "print(sst.shape, sst.size)\n",
    "\n",
    "for d in sst.dimensions:\n",
    "    print(d, len(d))\n",
    "\n",
    "for attr in sst.ncattrs():\n",
    "    print(f\"{attr} = {getattr(sst, attr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's extract some data and its related coordinate information and metadata.\n",
    "\n",
    "Using the `sst` variable from before, take a slice of `sst` as follows and assign it the variable `arr`:\n",
    "\n",
    "```python\n",
    "sst[1, 0, 10:20, 30:35]\n",
    "```\n",
    "\n",
    "- Print what type of object `arr` is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ma.core.MaskedArray'>\n"
     ]
    }
   ],
   "source": [
    "arr = sst[1,0,10:20, 30:35]\n",
    "print(type(arr))\n",
    "# print(f\"{np.array2string(arr, formatter={'float': lambda x: f'{x:.2f}'})}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Assign and print the list of `dimensions` from `sst` to the variable `dims`.\n",
    "Assign the `variables` dictionary of the Dataset, `ds`, to the variables `vars`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('time', 'surface', 'latitude', 'longitude')\n"
     ]
    }
   ],
   "source": [
    "dims = sst.dimensions\n",
    "\n",
    "vars = ds.variables\n",
    "\n",
    "print(dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now extract the slices from each Dataset variable in `vars` matching those in `arr`\n",
    "(i.e. matching the values in slice `[1, 0, 10:20, 30:35]` to the values in list `dims`).\n",
    "\n",
    "Assign them to the following variables:\n",
    "\n",
    "- Assign `time` slice to `arr_time`\n",
    "- Assign `surface` slice to `arr_level`\n",
    "- Assign `latitude` slice to `arr_lats`\n",
    "- Assign `longitude` slice to `arr_lons`\n",
    "\n",
    "Print the four new variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4,), (1,), (256,), (512,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['time'].shape,vars['surface'].shape,vars['latitude'].shape,vars['longitude'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "arr_time = vars['time'][1]\n",
    "arr_level = vars['surface'][0]\n",
    "arr_lats = vars['latitude'][10:20]\n",
    "arr_lons = vars['longitude'][30:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(data=[0.],\n",
       "             mask=False,\n",
       "       fill_value=1e+20,\n",
       "            dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars['surface'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at time   0.25 \n",
      " and depth =  0.0 \n",
      " the longitude are  [82.45532  81.75363  81.05194  80.350235 79.64853  78.94681  78.245094\n",
      " 77.543365 76.84164  76.13991 ] \n",
      " and the latitudes are [21.09375  21.796875 22.5      23.203125 23.90625 ] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('at time  ',arr_time, '\\n',\n",
    "      'and depth = ',arr_level,'\\n',\n",
    "      'the longitude are ', arr_lats, '\\n',\n",
    "      'and the latitudes are', arr_lons, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty dictionary called `metadata`, Loop through the NetCDF Variable attributes of `sst` and copy them into this new dictionary.\n",
    "Use the method as before to get name and value from `sst` and assign them to the key and value of the dictionary.\n",
    "\n",
    "Print the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['long_name',\n",
       " 'units',\n",
       " 'grid_type',\n",
       " '_FillValue',\n",
       " 'source',\n",
       " 'name',\n",
       " 'title',\n",
       " 'date',\n",
       " 'time']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sst.ncattrs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "NetCDF: Attribute not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [147]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvariable\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSSTK\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:3014\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__getattr__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2956\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.getncattr\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:1482\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._get_att\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:1965\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: NetCDF: Attribute not found"
     ]
    }
   ],
   "source": [
    "ds.variable['SSTK']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "netcdf ggas2014121200_00-18 {\n",
      "dimensions:\n",
      "\tlongitude = 512 ;\n",
      "\tlatitude = 256 ;\n",
      "\tsurface = 1 ;\n",
      "\ttime = UNLIMITED ; // (4 currently)\n",
      "variables:\n",
      "\tfloat longitude(longitude) ;\n",
      "\t\tlongitude:standard_name = \"longitude\" ;\n",
      "\t\tlongitude:long_name = \"longitude\" ;\n",
      "\t\tlongitude:units = \"degrees_east\" ;\n",
      "\t\tlongitude:axis = \"X\" ;\n",
      "\tfloat latitude(latitude) ;\n",
      "\t\tlatitude:standard_name = \"latitude\" ;\n",
      "\t\tlatitude:long_name = \"latitude\" ;\n",
      "\t\tlatitude:units = \"degrees_north\" ;\n",
      "\t\tlatitude:axis = \"Y\" ;\n",
      "\tfloat surface(surface) ;\n",
      "\t\tsurface:long_name = \"surface\" ;\n",
      "\t\tsurface:units = \"level\" ;\n",
      "\t\tsurface:axis = \"Z\" ;\n",
      "\tdouble time(time) ;\n",
      "\t\ttime:standard_name = \"time\" ;\n",
      "\t\ttime:units = \"days since 2014-12-12 00:00:00\" ;\n",
      "\t\ttime:calendar = \"standard\" ;\n",
      "\tfloat CI(time, surface, latitude, longitude) ;\n",
      "\t\tCI:long_name = \"Sea-ice cover\" ;\n",
      "\t\tCI:units = \"(0 - 1)\" ;\n",
      "\t\tCI:grid_type = \"gaussian\" ;\n",
      "\t\tCI:_FillValue = 2.e+20f ;\n",
      "\t\tCI:source = \"GRIB data\" ;\n",
      "\t\tCI:name = \"CI\" ;\n",
      "\t\tCI:title = \"Sea-ice cover\" ;\n",
      "\t\tCI:date = \"12/12/14\" ;\n",
      "\t\tCI:time = \"00:00\" ;\n",
      "\tfloat SSTK(time, surface, latitude, longitude) ;\n",
      "\t\tSSTK:long_name = \"Sea surface temperature\" ;\n",
      "\t\tSSTK:units = \"K\" ;\n",
      "\t\tSSTK:grid_type = \"gaussian\" ;\n",
      "\t\tSSTK:_FillValue = 2.e+20f ;\n",
      "\t\tSSTK:source = \"GRIB data\" ;\n",
      "\t\tSSTK:name = \"SSTK\" ;\n",
      "\t\tSSTK:title = \"Sea surface temperature\" ;\n",
      "\t\tSSTK:date = \"12/12/14\" ;\n",
      "\t\tSSTK:time = \"00:00\" ;\n",
      "\tfloat MSL(time, surface, latitude, longitude) ;\n",
      "\t\tMSL:standard_name = \"air_pressure_at_sea_level\" ;\n",
      "\t\tMSL:long_name = \"Mean sea-level pressure\" ;\n",
      "\t\tMSL:units = \"Pa\" ;\n",
      "\t\tMSL:grid_type = \"gaussian\" ;\n",
      "\t\tMSL:_FillValue = 2.e+20f ;\n",
      "\t\tMSL:source = \"GRIB data\" ;\n",
      "\t\tMSL:name = \"MSL\" ;\n",
      "\t\tMSL:title = \"Mean sea-level pressure\" ;\n",
      "\t\tMSL:date = \"12/12/14\" ;\n",
      "\t\tMSL:time = \"00:00\" ;\n",
      "\tfloat TCC(time, surface, latitude, longitude) ;\n",
      "\t\tTCC:standard_name = \"cloud_area_fraction\" ;\n",
      "\t\tTCC:long_name = \"Total cloud cover\" ;\n",
      "\t\tTCC:units = \"(0 - 1)\" ;\n",
      "\t\tTCC:grid_type = \"gaussian\" ;\n",
      "\t\tTCC:_FillValue = 2.e+20f ;\n",
      "\t\tTCC:source = \"GRIB data\" ;\n",
      "\t\tTCC:name = \"TCC\" ;\n",
      "\t\tTCC:title = \"Total cloud cover\" ;\n",
      "\t\tTCC:date = \"12/12/14\" ;\n",
      "\t\tTCC:time = \"00:00\" ;\n",
      "\tfloat U10(time, surface, latitude, longitude) ;\n",
      "\t\tU10:standard_name = \"eastward_wind\" ;\n",
      "\t\tU10:long_name = \"10 metre U wind component\" ;\n",
      "\t\tU10:units = \"m s**-1\" ;\n",
      "\t\tU10:grid_type = \"gaussian\" ;\n",
      "\t\tU10:_FillValue = 2.e+20f ;\n",
      "\t\tU10:source = \"GRIB data\" ;\n",
      "\t\tU10:name = \"U10\" ;\n",
      "\t\tU10:title = \"10 metre U wind component\" ;\n",
      "\t\tU10:date = \"12/12/14\" ;\n",
      "\t\tU10:time = \"00:00\" ;\n",
      "\tfloat V10(time, surface, latitude, longitude) ;\n",
      "\t\tV10:standard_name = \"northward_wind\" ;\n",
      "\t\tV10:long_name = \"10 metre V wind component\" ;\n",
      "\t\tV10:units = \"m s**-1\" ;\n",
      "\t\tV10:grid_type = \"gaussian\" ;\n",
      "\t\tV10:_FillValue = 2.e+20f ;\n",
      "\t\tV10:source = \"GRIB data\" ;\n",
      "\t\tV10:name = \"V10\" ;\n",
      "\t\tV10:title = \"10 metre V wind component\" ;\n",
      "\t\tV10:date = \"12/12/14\" ;\n",
      "\t\tV10:time = \"00:00\" ;\n",
      "\tfloat SKT(time, surface, latitude, longitude) ;\n",
      "\t\tSKT:long_name = \"Skin temperature\" ;\n",
      "\t\tSKT:units = \"K\" ;\n",
      "\t\tSKT:grid_type = \"gaussian\" ;\n",
      "\t\tSKT:_FillValue = 2.e+20f ;\n",
      "\t\tSKT:source = \"GRIB data\" ;\n",
      "\t\tSKT:name = \"SKT\" ;\n",
      "\t\tSKT:title = \"Skin temperature\" ;\n",
      "\t\tSKT:date = \"12/12/14\" ;\n",
      "\t\tSKT:time = \"00:00\" ;\n",
      "\n",
      "// global attributes:\n",
      "\t\t:CDI = \"Climate Data Interface version 1.5.6 (http://code.zmaw.de/projects/cdi)\" ;\n",
      "\t\t:Conventions = \"CF-1.4\" ;\n",
      "\t\t:history = \"Fri Apr 10 10:42:46 2015: cdo selname,SSTK,CI,U10,V10,TCC,SKT,MSL example_data/ggas2014121200_00-18_all_vars.nc example_data/ggas2014121200_00-18.nc\\n\",\n",
      "\t\t\t\"Fri Apr 10 10:42:13 2015: cdo mergetime /badc/ecmwf-era-interim/data/gg/as/2014/12/12/ggas201412120000.nc /badc/ecmwf-era-interim/data/gg/as/2014/12/12/ggas201412120600.nc /badc/ecmwf-era-interim/data/gg/as/2014/12/12/ggas201412121200.nc /badc/ecmwf-era-interim/data/gg/as/2014/12/12/ggas201412121800.nc example_data/ggas2014121200_00-18_all_vars.nc\\n\",\n",
      "\t\t\t\"Sun Jan 11 11:15:19 GMT 2015 - CONVSH V1.92 16-February-2006\" ;\n",
      "\t\t:CDO = \"Climate Data Operators version 1.5.6.1 (http://code.zmaw.de/projects/cdo)\" ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "!ncdump -h ../example_data/ggas2014121200_00-18.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's write the data/metadata from the previous section to a new NetCDF file\n",
    "\n",
    "In this section, we will define our own Variables, Dimensions, Attributes and save them as a NetCDF file.\n",
    "\n",
    "To start, import numpy as np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from numpy.random import uniform\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import num2date, date2num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open a new netCDF `Dataset` for writing to a file: \"mydata.nc\", specify the `mode` as write with \"w\" and the `format` as \"NETCDF4_CLASSIC\"\n",
    "Assign this to the variable `myds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/users/train023/my-isc-work/python-data/notebooks'"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "myds = Dataset('mydata.nc', 'w', format='NETCDF4_CLASSIC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create four new Dimensions to `myds` from your previous slices. Re-use the names from the last section.\n",
    "Note that the \"level\" and \"time\" Dimensions should have length, \"lat\" length 10 and \"lon\" length 5.\n",
    "To create a new Dimension use `myds.createDimension(name, size)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "time = myds.createDimension('time', 1)\n",
    "level = myds.createDimension('level', 1)\n",
    "lat = myds.createDimension('lat', 10)\n",
    "lon = myds.createDimension('lon', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create four Variables from those dimensions and assign them following this example for times:\n",
    "\n",
    "```python\n",
    "times = myds.createVariable('times', np.float64, ('time',))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "NetCDF: String match to name in use",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [178]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m times \u001b[38;5;241m=\u001b[39m \u001b[43mmyds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreateVariable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimes\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m levels \u001b[38;5;241m=\u001b[39m myds\u001b[38;5;241m.\u001b[39mcreateVariable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevels\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mfloat64, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m,))\n\u001b[1;32m      3\u001b[0m lats \u001b[38;5;241m=\u001b[39m myds\u001b[38;5;241m.\u001b[39mcreateVariable(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlats\u001b[39m\u001b[38;5;124m'\u001b[39m,  np\u001b[38;5;241m.\u001b[39mfloat64, (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m,))\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2838\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.createVariable\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:3985\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Variable.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:1965\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: NetCDF: String match to name in use"
     ]
    }
   ],
   "source": [
    "times = myds.createVariable('times', np.float64, ('time',))\n",
    "levels = myds.createVariable('levels', np.float64, ('level',))\n",
    "lats = myds.createVariable('lats',  np.float64, ('lat',))\n",
    "lons = myds.createVariable('lons',  np.float64, ('lon',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create `myvar` as a new Dataset Variable, with id \"temp\", type \"np.float64\", and dimensions: \"time\", \"level\", \"lat\", \"lon\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "myvar = myds.createVariable(\"temp\", np.float64, ('time', 'level', 'lat', 'lon',))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove the `_FillValue` value in the `metadata` dictionary.\n",
    "The next step will not work unless we do this.\n",
    "Fill values should be handled when the Variable is created, but we are ignoring that for this example.\n",
    "\n",
    "Use `del` to remove the `_FillValue` from `metadata`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [184]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[43mmetadata\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_FillValue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "del metadata['_FillValue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Write Variable attributes from the key/value pairs found in the input data (held in the `metadata` dictionary) to `myvar`.\n",
    "Use `myvar.setncattr(key, value)` to write attributes to the Dataset.\n",
    "\n",
    "Write one more global attribute \"source\" to `myds`. Set the attribute `source` to the value \"super dataset\".\n",
    "Use `myds.source` to create and set the value to the global attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'metadata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [185]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmetadata\u001b[49m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      2\u001b[0m     myvar\u001b[38;5;241m.\u001b[39msetncattr(key, value)\n\u001b[1;32m      4\u001b[0m myds\u001b[38;5;241m.\u001b[39msource \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msuper dataset\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'metadata' is not defined"
     ]
    }
   ],
   "source": [
    "for (key, value) in metadata.items():\n",
    "    myvar.setncattr(key, value)\n",
    "\n",
    "myds.source = \"super dataset\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Assign the `arr` array from before to `myvar[:]`\n",
    "\n",
    "Write some data values to each of your four spatio-temporal variables you created.\n",
    "Use simple lists of integers for these.\n",
    "Make sure they are the right length matching the slices from the previous section,\n",
    "use the index `[:]` on your `myds` Variables and assign the created array variables to them.\n",
    "\n",
    "Lastly close the Dataset, `myds`, to save the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'myvar' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [168]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmyvar\u001b[49m[:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m      4\u001b[0m myds\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'myvar' is not defined"
     ]
    }
   ],
   "source": [
    "myvar[:] = ...\n",
    "\n",
    "\n",
    "myds.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view the file contents, you can use the Jasmin service to run the `$ ncdump mydata.nc` command from the directory where the file is saved. Alternatively, you can call out to the linux shell from a Notebook, using: \n",
    "\n",
    "```\n",
    "!ncdump mydata.nc\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 + Jaspy",
   "language": "python",
   "name": "jaspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
